{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sklearn\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import textblob\n",
    "import numpy\n",
    "from nltk.corpus import sentence_polarity\n",
    "import os\n",
    "import sys\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.metrics import ConfusionMatrix\n",
    "twtokenizer = TweetTokenizer()\n",
    "import re\n",
    "import math\n",
    "from nltk.classify.scikitlearn import SklearnClassifier \n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ayesha92ahmad/Downloads/School-work/NLP/Homework/final-project'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1654\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>pred_class</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>260097528899452929</td>\n",
       "      <td>595739778</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Won the match #getin . Plus, tomorrow is a ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>263791921753882624</td>\n",
       "      <td>83619901</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Some areas of New England could see the first ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>264194578381410304</td>\n",
       "      <td>805646850</td>\n",
       "      <td>negative</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>264041328420204544</td>\n",
       "      <td>380148734</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>263816256640126976</td>\n",
       "      <td>473936453</td>\n",
       "      <td>objective-OR-neutral</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>263722278712393728</td>\n",
       "      <td>917435460</td>\n",
       "      <td>positive</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>262936443171778560</td>\n",
       "      <td>55572169</td>\n",
       "      <td>positive</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>260486470828171265</td>\n",
       "      <td>44399968</td>\n",
       "      <td>objective-OR-neutral</td>\n",
       "      <td>Tina Fey &amp;amp; Amy Poehler are hosting the Gol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>262968617233162240</td>\n",
       "      <td>757209662</td>\n",
       "      <td>positive</td>\n",
       "      <td>Lunch from my new Lil spot ...THE COTTON BOWL ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>263790847424880641</td>\n",
       "      <td>420538325</td>\n",
       "      <td>positive</td>\n",
       "      <td>SNC Halloween Pr. Pumped. Let's work it for Su...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id1        id2            pred_class  \\\n",
       "0  260097528899452929  595739778               neutral   \n",
       "1  263791921753882624   83619901               neutral   \n",
       "2  264194578381410304  805646850              negative   \n",
       "3  264041328420204544  380148734               neutral   \n",
       "4  263816256640126976  473936453  objective-OR-neutral   \n",
       "5  263722278712393728  917435460              positive   \n",
       "6  262936443171778560   55572169              positive   \n",
       "7  260486470828171265   44399968  objective-OR-neutral   \n",
       "8  262968617233162240  757209662              positive   \n",
       "9  263790847424880641  420538325              positive   \n",
       "\n",
       "                                          tweet_text  \n",
       "0  Won the match #getin . Plus, tomorrow is a ver...  \n",
       "1  Some areas of New England could see the first ...  \n",
       "2                                      Not Available  \n",
       "3                                      Not Available  \n",
       "4                                      Not Available  \n",
       "5                                      Not Available  \n",
       "6                                      Not Available  \n",
       "7  Tina Fey &amp; Amy Poehler are hosting the Gol...  \n",
       "8  Lunch from my new Lil spot ...THE COTTON BOWL ...  \n",
       "9  SNC Halloween Pr. Pumped. Let's work it for Su...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fieldnames = [\"id1\", \"id2\",\"pred_class\",\"tweet_text\"]\n",
    "dataset=pd.read_csv(\"SemEval2014TweetData/corpus/downloaded-tweeti-b.dev.dist.tsv\", sep='\\t',names = fieldnames)\n",
    "print(len(dataset))\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filter out not available\n",
    "dataset= (dataset[dataset['tweet_text']!=\"Not Available\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1413, 1)\n",
      "(1413, 1)\n"
     ]
    }
   ],
   "source": [
    "np_tweets =dataset.as_matrix(columns=[\"tweet_text\"])\n",
    "np_pred= dataset.as_matrix(columns=[\"pred_class\"])\n",
    "print(np_tweets.shape)\n",
    "print(np_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"neutral\"', \"Won the match #getin . Plus, tomorrow is a very busy day, with Awareness Day's and debates. Gulp. Debates...\"]\n",
      "['\"neutral\"', 'Some areas of New England could see the first flakes of the season Tuesday.']\n",
      "['\"negative\"', 'Not Available']\n",
      "['\"neutral\"', 'Not Available']\n",
      "['\"objective-OR-neutral\"', 'Not Available']\n",
      "['\"positive\"', 'Not Available']\n",
      "['\"positive\"', 'Not Available']\n",
      "['\"objective-OR-neutral\"', 'Tina Fey &amp; Amy Poehler are hosting the Golden Globe awards on January 13. What do you think?']\n",
      "['\"positive\"', 'Lunch from my new Lil spot ...THE COTTON BOWL ....pretty good#1st#time#will be going back# http://t.co/Dbbj8xLZ']\n",
      "['\"positive\"', \"SNC Halloween Pr. Pumped. Let's work it for Sunday....Packers vs....who knows or caresn. #SNC #cheerpracticeonhalloween\"]\n",
      "[(['Won', 'the', 'match', '#getin', '.', 'Plus', ',', 'tomorrow', 'is', 'a', 'very', 'busy', 'day', ',', 'with', 'Awareness', \"Day's\", 'and', 'debates', '.', 'Gulp', '.', 'Debates', '...'], 'neu'), (['Some', 'areas', 'of', 'New', 'England', 'could', 'see', 'the', 'first', 'flakes', 'of', 'the', 'season', 'Tuesday', '.'], 'neu'), (['Tina', 'Fey', '&', 'Amy', 'Poehler', 'are', 'hosting', 'the', 'Golden', 'Globe', 'awards', 'on', 'January', '13', '.', 'What', 'do', 'you', 'think', '?'], 'neu'), (['Lunch', 'from', 'my', 'new', 'Lil', 'spot', '...', 'THE', 'COTTON', 'BOWL', '...', 'pretty', 'good', '#1st', '#time', '#will', 'be', 'going', 'back', '#', 'http://t.co/Dbbj8xLZ'], 'pos')]\n"
     ]
    }
   ],
   "source": [
    "f = open('SemEval2014TweetData/corpus/downloaded-tweeti-b.dev.dist.tsv', 'r')\n",
    "stopwords = open('SemEval2014TweetData/stopwords_twitter.txt', 'r')\n",
    "stoptokens = nltk.word_tokenize(stopwords.read())\n",
    "  # loop over lines in the file and use the first limit of them\n",
    "  #    assuming that the tweets are sufficiently randomized\n",
    "tweetdata = []\n",
    "for line in f:\n",
    "    if (len(tweetdata) < 10000):\n",
    "    # remove final end of line character\n",
    "        line = line.strip()\n",
    "  # each line has 4 items separated by tabs\n",
    "  # ignore the tweet and user ids, and keep the sentiment and tweet text\n",
    "        tweetdata.append(line.split('\\t')[2:4])\n",
    "\n",
    "for tweet in tweetdata[:10]:\n",
    "    print (tweet)\n",
    "\n",
    "# create list of tweet documents as (list of words, label)\n",
    "# where the labels are condensed to just 3:  'pos', 'neg', 'neu'\n",
    "tweetdocs = []\n",
    "# add all the tweets except the ones whose text is Not Available\n",
    "for tweet in tweetdata:\n",
    "    if (tweet[1] != 'Not Available'):\n",
    "      # run the tweet tokenizer on the text string - returns unicode tokens, so convert to utf8\n",
    "        tokens = twtokenizer.tokenize(tweet[1])\n",
    "        if tweet[0] == '\"positive\"':\n",
    "            label = 'pos'\n",
    "        else:\n",
    "            if tweet[0] == '\"negative\"':\n",
    "                label = 'neg'\n",
    "            else:\n",
    "                if (tweet[0] == '\"neutral\"') or (tweet[0] == '\"objective\"') or (tweet[0] == '\"objective-OR-neutral\"'):\n",
    "                    label = 'neu'\n",
    "                else:\n",
    "                    label = ''\n",
    "        tweetdocs.append((tokens, label))\n",
    "  \n",
    "  # print a few\n",
    "print(tweetdocs[:4])    \n",
    "\n",
    "\n",
    "# for tweet,label in tweetdocs[:10]:\n",
    "#     print(tweet)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function that takes a word and returns true if it consists only\n",
    "#   of non-alphabetic characters  (assumes import re)\n",
    "def alpha_filter(w):\n",
    "  # pattern to match word of non-alphabetical characters\n",
    "    pattern = re.compile('^[^a-z]+$')\n",
    "    if (pattern.match(w)):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['won', 'match', '#getin', 'plus', 'tomorrow', 'busy', 'day', 'awareness', \"day's\", 'debates', 'gulp', 'debates'], 'neu'), (['areas', 'new', 'england', 'see', 'first', 'flakes', 'season', 'tuesday'], 'neu'), (['tina', 'fey', 'amy', 'poehler', 'hosting', 'golden', 'globe', 'awards', 'january', 'think'], 'neu'), (['lunch', 'new', 'lil', 'spot', 'cotton', 'bowl', 'pretty', 'good', '#1st', '#time', '#will', 'going', 'back', 'http://t.co/dbbj8xlz'], 'pos'), (['snc', 'halloween', 'pr', 'pumped', 'work', 'sunday', 'packers', 'vs', 'knows', 'caresn', '#snc', '#cheerpracticeonhalloween'], 'pos'), (['@jacquelinemegan', 'sorry', 'heart', 'paris', 'no', 'longer', 'available', 'rockwell', 'branch', 'may', 'call', 'get', 'copy', 'transferred'], 'neg'), (['manchester', 'united', 'will', 'try', 'return', 'winning', 'ways', 'face', 'arsenal', 'premier', 'league', 'old', 'trafford', 'saturday'], 'neu'), (['going', 'bulls', 'game', 'aaliyah', 'hope', 'next', 'thursday'], 'neu'), (['toon', 'fans', 'spare', 'ticket', 'anfield', 'sunday', 'willing', 'pay', 'extra', '#nufc'], 'neu'), (['louis', 'inspired', 'outfit', 'monday', 'zayn', 'inspired', 'outfit', 'today', 'done', 'just', 'need', 'harry'], 'pos'), (['going', 'bed', 'now', 'rose', 'parade', 'game', 'tomorrow'], 'neu'), (['@_nenaah', 'oh', 'cause', 'friend', 'got', 'something', 'china', 'said', 'will', 'take', 'least', 'weeks', 'came', '2nd', 'week', ':p'], 'neu'), (['love', 'banner', 'unfurled', 'united', 'end', 'last', 'night', 'read', 'chelsea', 'standing', 'racism', 'since', 'sunday'], 'pos'), (['#repost', 'chris', 'bosh', 'may', 'ugly', 'gorgeous', 'wife', 'adorbs', 'baby', 'want', 'happy', 'like', 'one', 'http://t.co/s6moxr1u'], 'pos'), (['@prodnose', 'one', 'little', 'jokes', 'like', 'elvis', 'playing', 'marquee', 'next', 'tuesday'], 'neg'), (['gold', 'edges', 'ahead', 'us', 'jobs', 'data', 'singapore', 'reuters', 'gold', 'edged', 'lower', 'friday', 'investors', 'waiting', 'http://t.co/ciqfona1'], 'neg'), (['@numenssoccer', 'another', 'close-range', 'iu', 'shot', 'goes', 'high', 'kyle', 'schickel', 'checks', 'missimo', 'kyle', 'missed', 'wisconsin', 'game', 'last', 'sunday'], 'neu'), (['shaw', \"wouldn't\", 'let', 'luck', 'throw', 'late', 'fiesta', 'bowl', 'fine', 'nunes', 'throwing', 'fade', 'route', '4th', 'w', 'left'], 'neu'), (['monday', 'leave', 'singapore', 'going', 'post', 'something', 'might', 'offensive'], 'neg'), (['abc', '@jaketapper', 'country', 'music', 'awards', 'may', 'still', 'little', 'credibility', 'come', 'wednesday', '#tcot'], 'pos')]\n"
     ]
    }
   ],
   "source": [
    "# first preprocessing and then possibly filter tokens\n",
    "processed_tweets=[]\n",
    "for tweet,label in tweetdocs:\n",
    "    x= [w.lower() for w in tweet]\n",
    "    x= [w for w in x if not alpha_filter(w)]\n",
    "    x= [w for w in x if not w in stoptokens]\n",
    "    processed_tweets.append((x,label))\n",
    "print(processed_tweets[:20])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Won', 'the', 'match', '#getin', '.', 'Plus', ',', 'tomorrow', 'is', 'a', 'very', 'busy', 'day', ',', 'with', 'Awareness', \"Day's\", 'and', 'debates', '.', 'Gulp', '.', 'Debates', '...', 'Some', 'areas', 'of', 'New', 'England', 'could', 'see', 'the', 'first', 'flakes', 'of', 'the', 'season', 'Tuesday', '.', 'Tina', 'Fey', '&', 'Amy', 'Poehler', 'are', 'hosting', 'the', 'Golden', 'Globe', 'awards', 'on', 'January', '13', '.', 'What', 'do', 'you', 'think', '?', 'Lunch', 'from', 'my', 'new', 'Lil', 'spot', '...', 'THE', 'COTTON', 'BOWL', '...', 'pretty', 'good', '#1st', '#time', '#will', 'be', 'going', 'back', '#', 'http://t.co/Dbbj8xLZ', 'SNC', 'Halloween', 'Pr', '.', 'Pumped', '.', \"Let's\", 'work', 'it', 'for', 'Sunday', '...', 'Packers', 'vs', '...', 'who', 'knows', 'or', 'caresn', '.']\n"
     ]
    }
   ],
   "source": [
    "# continue as usual to get all words and create word features\n",
    "\n",
    "# get all words from all tweet and put into a frequency distribution\n",
    "#   note lowercase, but no stemming or stopwords\n",
    "all_words_list = [word for (tweet,label) in tweetdocs for word in tweet]\n",
    "\n",
    "print(all_words_list[:100])\n",
    "all_words = nltk.FreqDist(all_words_list)\n",
    "# get the 2000 most frequently appearing keywords in the corpus\n",
    "word_items = all_words.most_common(2000)\n",
    "word_features = [word for (word,count) in word_items]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature sets from a feature definition function\n",
    "\n",
    "# define features (keywords) of a document for a BOW/unigram baseline\n",
    "# each feature is 'contains(keyword)' and is true or false depending\n",
    "# on whether that keyword is in the document\n",
    "def document_features(document, word_features):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get features sets for a document, including keyword features and category feature\n",
    "featuresets = [(document_features(d, word_features), c) for (d, c) in processed_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train and test a classifier\n",
    "num_docs = len(featuresets)\n",
    "#to create 80-10 split\n",
    "train_set, test_set = featuresets[:math.floor(0.8*num_docs)],featuresets[math.floor(0.8*num_docs):]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set Accuracy: 0.8619469026548673\n",
      "Test set Accuracy: 0.6042402826855123\n",
      "Most Informative Features\n",
      "          contains(best) = True              pos : neu    =     12.6 : 1.0\n",
      "         contains(can't) = True              neg : neu    =     12.3 : 1.0\n",
      "          contains(wait) = True              pos : neg    =      9.5 : 1.0\n",
      "          contains(gets) = True              neg : neu    =      9.2 : 1.0\n",
      "          contains(love) = True              pos : neu    =      8.5 : 1.0\n",
      "        contains(pretty) = True              neg : neu    =      7.2 : 1.0\n",
      "          contains(hate) = True              neg : pos    =      6.9 : 1.0\n",
      "           contains(bad) = True              neg : pos    =      6.9 : 1.0\n",
      "         contains(c'mon) = True              neg : pos    =      6.9 : 1.0\n",
      "          contains(yeah) = True              pos : neu    =      6.7 : 1.0\n",
      "         contains(power) = True              neg : neu    =      6.4 : 1.0\n",
      "        contains(didn't) = True              neg : neu    =      6.4 : 1.0\n",
      "          contains(fuck) = True              neg : neu    =      6.4 : 1.0\n",
      "          contains(lost) = True              neg : neu    =      6.4 : 1.0\n",
      "          contains(shit) = True              neg : neu    =      6.4 : 1.0\n",
      "          contains(live) = True              neu : pos    =      6.2 : 1.0\n",
      "          contains(luck) = True              pos : neu    =      5.8 : 1.0\n",
      "       contains(looking) = True              pos : neu    =      5.8 : 1.0\n",
      "          contains(high) = True              neu : pos    =      5.7 : 1.0\n",
      "         contains(don't) = True              neg : neu    =      5.7 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set Accuracy: \"+ str(nltk.classify.accuracy(classifier, train_set)))\n",
    "print(\"Test set Accuracy: \"+ str(nltk.classify.accuracy(classifier, test_set)))\n",
    "# show most informative features\n",
    "print(classifier.show_most_informative_features(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get features sets for a document, including keyword features and category feature\n",
    "featuresets = [(document_features(d, word_features), c) for (d, c) in tweetdocs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test a classifier\n",
    "num_docs = len(featuresets)\n",
    "#to create 90-10 split\n",
    "train_set, test_set = featuresets[:math.floor(0.9*num_docs)],featuresets[math.floor(0.9*num_docs):]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set Accuracy: 0.8977183320220299\n",
      "Test set Accuracy: 0.6408450704225352\n",
      "Most Informative Features\n",
      "            contains(:() = True              neg : neu    =     20.9 : 1.0\n",
      "       contains(excited) = True              pos : neu    =     12.0 : 1.0\n",
      "         contains(can't) = True              neg : neu    =     11.7 : 1.0\n",
      "          contains(best) = True              pos : neu    =     10.9 : 1.0\n",
      "          contains(wait) = True              pos : neg    =     10.0 : 1.0\n",
      "          contains(gets) = True              neg : neu    =      9.4 : 1.0\n",
      "         contains(don't) = True              neg : neu    =      9.4 : 1.0\n",
      "          contains(Good) = True              pos : neu    =      9.3 : 1.0\n",
      "         contains(Honey) = True              neg : pos    =      8.1 : 1.0\n",
      "         contains(C'mon) = True              neg : neu    =      7.9 : 1.0\n",
      "          contains(SOPA) = True              neg : neu    =      7.9 : 1.0\n",
      "          contains(love) = True              pos : neu    =      7.5 : 1.0\n",
      "        contains(didn't) = True              neg : neu    =      7.3 : 1.0\n",
      "         contains(won't) = True              neg : neu    =      7.1 : 1.0\n",
      "        contains(Jordan) = True              neg : pos    =      7.1 : 1.0\n",
      "          contains(does) = True              neg : pos    =      7.1 : 1.0\n",
      "        contains(Badger) = True              neg : pos    =      7.1 : 1.0\n",
      "            contains(:)) = True              pos : neg    =      6.8 : 1.0\n",
      "         contains(power) = True              neg : neu    =      6.5 : 1.0\n",
      "          contains(exam) = True              neg : neu    =      6.5 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "    print(\"Train set Accuracy: \"+ str(nltk.classify.accuracy(classifier, train_set)))\n",
    "    print(\"Test set Accuracy: \"+ str(nltk.classify.accuracy(classifier, test_set)))\n",
    "    # show most informative features\n",
    "    print(classifier.show_most_informative_features(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####   adding features from a sentiment lexicon   ####\n",
    "# First look at the program in the file Subjectivity.py to load the subjectivity lexicon\n",
    "# copy and paste the definition of the readSubjectivity function\n",
    "\n",
    "# this function returns a dictionary where you can look up words and get back \n",
    "#     the four items of subjectivity information described above\n",
    "def readSubjectivity(path):\n",
    "    flexicon = open(path, 'r')\n",
    "    # initialize an empty dictionary\n",
    "    sldict = { }\n",
    "    for line in flexicon:\n",
    "        fields = line.split()   # default is to split on whitespace\n",
    "        # split each field on the '=' and keep the second part as the value\n",
    "        strength = fields[0].split(\"=\")[1]\n",
    "        word = fields[2].split(\"=\")[1]\n",
    "        posTag = fields[3].split(\"=\")[1]\n",
    "        stemmed = fields[4].split(\"=\")[1]\n",
    "        polarity = fields[5].split(\"=\")[1]\n",
    "        if (stemmed == 'y'):\n",
    "            isStemmed = True\n",
    "        else:\n",
    "            isStemmed = False\n",
    "        # put a dictionary entry with the word as the keyword\n",
    "        #     and a list of the other values\n",
    "        sldict[word] = [strength, posTag, isStemmed, polarity]\n",
    "    return sldict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6885"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a path to where the subjectivity file resides on your disk\n",
    "\n",
    "# create your own path to the subjclues file\n",
    "SLpath = \"/Users/ayesha92ahmad/Downloads/School-work/NLP/Codes/LabExercises/subjclueslen1-HLTEMNLP05.tff\"\n",
    "SL = readSubjectivity(SLpath)\n",
    "\n",
    "# how many words are in the dictionary\n",
    "len(SL.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define features that include word counts of subjectivity words\n",
    "# negative feature will have number of weakly negative words +\n",
    "#    2 * number of strongly negative words\n",
    "# positive feature has similar definition\n",
    "#    not counting neutral words\n",
    "def SL_features(document, word_features, SL):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    # count variables for the 4 classes of subjectivity\n",
    "    weakPos = 0\n",
    "    strongPos = 0\n",
    "    weakNeg = 0\n",
    "    strongNeg = 0\n",
    "    for word in document_words:\n",
    "        if word in SL:\n",
    "            strength, posTag, isStemmed, polarity = SL[word]\n",
    "            if strength == 'weaksubj' and polarity == 'positive':\n",
    "                weakPos += 1\n",
    "            if strength == 'strongsubj' and polarity == 'positive':\n",
    "                strongPos += 1\n",
    "            if strength == 'weaksubj' and polarity == 'negative':\n",
    "                weakNeg += 1\n",
    "            if strength == 'strongsubj' and polarity == 'negative':\n",
    "                strongNeg += 1\n",
    "            features['positivecount'] = weakPos + (2 * strongPos)\n",
    "            features['negativecount'] = weakNeg + (2 * strongNeg)      \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "SL_featuresets = [(SL_features(d, word_features, SL), c) for (d, c) in tweetdocs]\n",
    "num_docs = len(featuresets)\n",
    "#to create 90-10 split\n",
    "train_set, test_set = SL_featuresets[:math.floor(0.9*num_docs)],SL_featuresets[math.floor(0.9*num_docs):]\n",
    "# retrain the classifier using these features\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set Accuracy: 0.8977183320220299\n",
      "Test set Accuracy: 0.6549295774647887\n",
      "Most Informative Features\n",
      "            contains(:() = True              neg : neu    =     20.9 : 1.0\n",
      "           negativecount = 3                 neg : pos    =     12.1 : 1.0\n",
      "       contains(excited) = True              pos : neu    =     12.0 : 1.0\n",
      "         contains(can't) = True              neg : neu    =     11.7 : 1.0\n",
      "          contains(best) = True              pos : neu    =     10.9 : 1.0\n",
      "          contains(wait) = True              pos : neg    =     10.0 : 1.0\n",
      "          contains(gets) = True              neg : neu    =      9.4 : 1.0\n",
      "         contains(don't) = True              neg : neu    =      9.4 : 1.0\n",
      "          contains(Good) = True              pos : neu    =      9.3 : 1.0\n",
      "         contains(Honey) = True              neg : pos    =      8.1 : 1.0\n",
      "         contains(C'mon) = True              neg : neu    =      7.9 : 1.0\n",
      "          contains(SOPA) = True              neg : neu    =      7.9 : 1.0\n",
      "          contains(love) = True              pos : neu    =      7.5 : 1.0\n",
      "        contains(didn't) = True              neg : neu    =      7.3 : 1.0\n",
      "         contains(won't) = True              neg : neu    =      7.1 : 1.0\n",
      "        contains(Jordan) = True              neg : pos    =      7.1 : 1.0\n",
      "          contains(does) = True              neg : pos    =      7.1 : 1.0\n",
      "        contains(Badger) = True              neg : pos    =      7.1 : 1.0\n",
      "            contains(:)) = True              pos : neg    =      6.8 : 1.0\n",
      "         contains(power) = True              neg : neu    =      6.5 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set Accuracy: \"+ str(nltk.classify.accuracy(classifier, train_set)))\n",
    "print(\"Test set Accuracy: \"+ str(nltk.classify.accuracy(classifier, test_set)))\n",
    "# show most informative features\n",
    "print(classifier.show_most_informative_features(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function takes a document list of words and returns a feature dictionary\n",
    "# it runs the default pos tagger (the Stanford tagger) on the document\n",
    "#   and counts 4 types of pos tags to use as features\n",
    "def POS_features(document, word_features):\n",
    "    document_words = set(document)\n",
    "    tagged_words = nltk.pos_tag(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    numNoun = 0\n",
    "    numVerb = 0\n",
    "    numAdj = 0\n",
    "    numAdverb = 0\n",
    "    for (word, tag) in tagged_words:\n",
    "        if tag.startswith('N'): numNoun += 1\n",
    "        if tag.startswith('V'): numVerb += 1\n",
    "        if tag.startswith('J'): numAdj += 1\n",
    "        if tag.startswith('R'): numAdverb += 1\n",
    "    features['nouns'] = numNoun\n",
    "    features['verbs'] = numVerb\n",
    "    features['adjectives'] = numAdj\n",
    "    features['adverbs'] = numAdverb\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "POS_featuresets = [(POS_features(d, word_features), c) for (d, c) in tweetdocs]\n",
    "# train and test the classifier\n",
    "num_docs = len(featuresets)\n",
    "#to create 90-10 split\n",
    "train_set, test_set = POS_featuresets[:math.floor(0.9*num_docs)],POS_featuresets[math.floor(0.9*num_docs):]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set Accuracy: 0.8859166011014948\n",
      "Test set Accuracy: 0.6267605633802817\n",
      "Most Informative Features\n",
      "            contains(:() = True              neg : neu    =     20.9 : 1.0\n",
      "       contains(excited) = True              pos : neu    =     12.0 : 1.0\n",
      "         contains(can't) = True              neg : neu    =     11.7 : 1.0\n",
      "          contains(best) = True              pos : neu    =     10.9 : 1.0\n",
      "          contains(wait) = True              pos : neg    =     10.0 : 1.0\n",
      "          contains(gets) = True              neg : neu    =      9.4 : 1.0\n",
      "         contains(don't) = True              neg : neu    =      9.4 : 1.0\n",
      "          contains(Good) = True              pos : neu    =      9.3 : 1.0\n",
      "         contains(Honey) = True              neg : pos    =      8.1 : 1.0\n",
      "         contains(C'mon) = True              neg : neu    =      7.9 : 1.0\n",
      "          contains(SOPA) = True              neg : neu    =      7.9 : 1.0\n",
      "          contains(love) = True              pos : neu    =      7.5 : 1.0\n",
      "        contains(didn't) = True              neg : neu    =      7.3 : 1.0\n",
      "         contains(won't) = True              neg : neu    =      7.1 : 1.0\n",
      "        contains(Jordan) = True              neg : pos    =      7.1 : 1.0\n",
      "          contains(does) = True              neg : pos    =      7.1 : 1.0\n",
      "        contains(Badger) = True              neg : pos    =      7.1 : 1.0\n",
      "            contains(:)) = True              pos : neg    =      6.8 : 1.0\n",
      "         contains(power) = True              neg : neu    =      6.5 : 1.0\n",
      "          contains(exam) = True              neg : neu    =      6.5 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set Accuracy: \"+ str(nltk.classify.accuracy(classifier, train_set)))\n",
    "print(\"Test set Accuracy: \"+ str(nltk.classify.accuracy(classifier, test_set)))\n",
    "# show most informative features\n",
    "print(classifier.show_most_informative_features(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CV_Scores(classifier_type, test_set):\n",
    "    from collections import Counter\n",
    "    from nltk.metrics import ConfusionMatrix\n",
    "    refList = []\n",
    "    testList = []\n",
    "    for features, label in test_set:\n",
    "        refList.append(label)\n",
    "        testList.append(classifier_type.classify(features))\n",
    "    cm = ConfusionMatrix(refList, testList)\n",
    "    true_positives = Counter()\n",
    "    false_negatives = Counter()\n",
    "    false_positives = Counter()\n",
    "    for i in refList:\n",
    "        for j in refList:\n",
    "            if i == j:\n",
    "                true_positives[i] += cm[i,j]\n",
    "            else:\n",
    "                false_negatives[i] += cm[i,j]\n",
    "                false_positives[j] += cm[i,j]\n",
    "    #print \"Confusion Matrix:\"\n",
    "    #print cm\n",
    "    precision=0\n",
    "    recall=0\n",
    "    fscore=0\n",
    "    for i in sorted(refList):\n",
    "        if true_positives[i] == 0:\n",
    "            fscore = 0\n",
    "        else:\n",
    "            precision = true_positives[i] / float(true_positives[i]+false_positives[i])\n",
    "            recall = true_positives[i] / float(true_positives[i]+false_negatives[i])\n",
    "            fscore = 2 * (precision * recall) / float(precision + recall)\n",
    "    return precision, recall , fscore\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## cross-validation ##\n",
    "# this function takes the number of folds, the feature sets\n",
    "# it iterates over the folds, using different sections for training and testing in turn\n",
    "#   it prints the accuracy for each fold and the average accuracy at the end\n",
    "def cross_validation_accuracy(num_folds, featuresets):\n",
    "    subset_size = int(len(featuresets)/num_folds)\n",
    "    accuracy_train_list = []\n",
    "    accuracy_test_list = []\n",
    "    presion_list=[]\n",
    "    recall_list=[]\n",
    "    fscore_list=[]\n",
    "    # iterate over the folds\n",
    "    for i in range(num_folds):\n",
    "        test_this_round = featuresets[(i*subset_size):][:subset_size]\n",
    "        train_this_round = featuresets[:(i*subset_size)] + featuresets[((i+1)*subset_size):]\n",
    "        # train using train_this_round\n",
    "        classifier = nltk.NaiveBayesClassifier.train(train_this_round)\n",
    "        # evaluate against test_this_round and save accuracy\n",
    "        accuracy_train_this_round = nltk.classify.accuracy(classifier, train_this_round)\n",
    "        accuracy_test_this_round = nltk.classify.accuracy(classifier, test_this_round)\n",
    "        accuracy_train_list.append(accuracy_train_this_round)\n",
    "        accuracy_test_list.append(accuracy_test_this_round)\n",
    "        precision, recall,fscore =CV_Scores(classifier, test_set)\n",
    "        presion_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        fscore_list.append(fscore)\n",
    "    # find mean accuracy over all rounds\n",
    "    print ('mean train accuracy', sum(accuracy_train_list) / num_folds)\n",
    "    print ('mean test accuracy', sum(accuracy_test_list) / num_folds)\n",
    "    print ('mean precision', sum(presion_list) / num_folds)\n",
    "    print ('mean recall', sum(recall_list) / num_folds)\n",
    "    print ('mean fscore', sum(fscore_list) / num_folds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean train accuracy 0.8945754716981134\n",
      "mean test accuracy 0.5943262411347517\n",
      "mean precision 0.9241287740272014\n",
      "mean recall 0.9239049496531809\n",
      "mean fscore 0.9228843189217599\n"
     ]
    }
   ],
   "source": [
    "#kfold on SL feature\n",
    "cross_validation_accuracy(10,SL_featuresets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean train accuracy 0.8907232704402516\n",
      "mean test accuracy 0.5836879432624114\n",
      "mean precision 0.9523414224100055\n",
      "mean recall 0.8972381841093219\n",
      "mean fscore 0.9234335668853223\n"
     ]
    }
   ],
   "source": [
    "#Kfold on POS feature\n",
    "cross_validation_accuracy(10,POS_featuresets )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean train accuracy 0.896305031446541\n",
      "mean test accuracy 0.5780141843971631\n",
      "mean precision 0.9241287740272014\n",
      "mean recall 0.9239049496531809\n",
      "mean fscore 0.9228843189217599\n"
     ]
    }
   ],
   "source": [
    "#Kfold on POS feature\n",
    "cross_validation_accuracy(10,featuresets )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## cross-validation ##\n",
    "# this function takes the number of folds, the feature sets\n",
    "# it iterates over the folds, using different sections for training and testing in turn\n",
    "#   it prints the accuracy for each fold and the average accuracy at the end\n",
    "def cross_validation_accuracy_SKlearn(num_folds, featuresets):\n",
    "    subset_size = int(len(featuresets)/num_folds)\n",
    "    accuracy_train_list = []\n",
    "    accuracy_test_list = []\n",
    "    presion_list=[]\n",
    "    recall_list=[]\n",
    "    fscore_list=[]\n",
    "    # iterate over the folds\n",
    "    for i in range(num_folds):\n",
    "        test_this_round = featuresets[(i*subset_size):][:subset_size]\n",
    "        train_this_round = featuresets[:(i*subset_size)] + featuresets[((i+1)*subset_size):]\n",
    "        # train using train_this_round\n",
    "        classifier = SklearnClassifier(MultinomialNB())\n",
    "        classifier.train(train_this_round)\n",
    "        \n",
    "        # evaluate against test_this_round and save accuracy\n",
    "        accuracy_train_this_round = nltk.classify.accuracy(classifier, train_this_round)\n",
    "        accuracy_test_this_round = nltk.classify.accuracy(classifier, test_this_round)\n",
    "        accuracy_train_list.append(accuracy_train_this_round)\n",
    "        accuracy_test_list.append(accuracy_test_this_round)\n",
    "        precision, recall,fscore =CV_Scores(classifier, test_set)\n",
    "        presion_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        fscore_list.append(fscore)\n",
    "    # find mean accuracy over all rounds\n",
    "    print ('mean train accuracy', sum(accuracy_train_list) / num_folds)\n",
    "    print ('mean test accuracy', sum(accuracy_test_list) / num_folds)\n",
    "    print ('mean precision', sum(presion_list) / num_folds)\n",
    "    print ('mean recall', sum(recall_list) / num_folds)\n",
    "    print ('mean fscore', sum(fscore_list) / num_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean train accuracy 0.8875786163522014\n",
      "mean test accuracy 0.5794326241134751\n",
      "mean precision 0.9245023014193092\n",
      "mean recall 0.9382635383635284\n",
      "mean fscore 0.9307603702136215\n"
     ]
    }
   ],
   "source": [
    "#Kfold on document feature on multinomial naive bayes classifier\n",
    "cross_validation_accuracy_SKlearn(10,featuresets )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
